{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVRZW8cXL4aj2lD8bj9nS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SigneGitSand/Stanford_SkinScan/blob/main/SkinScan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necesary dependencies:"
      ],
      "metadata": {
        "id": "107CLb-iSjw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install PIL\n",
        "!pip install streamlit pyngrok\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "zNfNBzIqSomH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract text to generate knowledge base"
      ],
      "metadata": {
        "id": "uU9ua0X7YKQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "2Z7GPbiFd4fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "print(fitz.__doc__)\n",
        "print(fitz.__file__)\n",
        "\n",
        "def extract_text_chunks(pdf_path, chunk_size=500):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += page.get_text()\n",
        "\n",
        "    # Simple chunking by characters\n",
        "    chunks = [full_text[i:i+chunk_size] for i in range(0, len(full_text), chunk_size)]\n",
        "    return chunks\n",
        "\n",
        "pdfs_for_knowledge = [\"/content/cancer-org.pdf\", \"/content/MIA.pdf\"]\n",
        "knowledge_texts = []\n",
        "for pdf in pdfs_for_knowledge:\n",
        "    knowledge_texts.extend(extract_text_chunks(pdf))"
      ],
      "metadata": {
        "id": "9VflmyPtYJGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize the knowledge text:"
      ],
      "metadata": {
        "id": "J3QQyscZfXIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "bqXy9iy5gNH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Vectorize the extracted chunks\n",
        "embeddings = model.encode(knowledge_texts, convert_to_tensor=True, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "7r5UzODQfWMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "def get_top_k_chunks(text_note, k=2):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Embed the input note\n",
        "    note_embedding = model.encode(text_note, convert_to_tensor=True, device=device)\n",
        "\n",
        "    # Ensure knowledge embeddings are on the same device\n",
        "    embeddings_tensor = torch.tensor(embeddings, device=device)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = util.cos_sim(note_embedding, embeddings_tensor)[0]\n",
        "\n",
        "    # Get top-k most similar chunk indices\n",
        "    top_k_idx = similarities.topk(k=k).indices\n",
        "\n",
        "    # Return top-k chunks and scores\n",
        "    top_chunks = [(knowledge_texts[i], float(similarities[i])) for i in top_k_idx]\n",
        "    return top_chunks"
      ],
      "metadata": {
        "id": "bhETPZOxi37U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test encoder\n",
        "text = \"My mole is hurting and is growing in a weird shape\"\n",
        "\n",
        "top_chunks = get_top_k_chunks(text)\n",
        "\n",
        "print(top_chunks)"
      ],
      "metadata": {
        "id": "IMJxOaXXlKgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "def generate_llm_diagnosis(user_note, label, chunk_1, chunk_2, model=\"mistralai/mistral-medium-3\"):\n",
        "    # Get API key from environment variable instead of interactive prompt\n",
        "    api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "    # If no API key is available, return a default message\n",
        "    if not api_key:\n",
        "        return f\"API key not found. To enable detailed analysis, please set the OPENROUTER_API_KEY environment variable.\\n\\nBased on the image classification: This appears to be {label}. Please consult a healthcare professional for proper diagnosis.\"\n",
        "\n",
        "    prompt = f\"\"\"You are a medical AI assistant helping a user who uploaded a photo of their skin lesion. The image classifier predicted the lesion is: {label}.\n",
        "\n",
        "User notes:\n",
        "{user_note}\n",
        "\n",
        "Relevant medical knowledge:\n",
        "1. {chunk_1}\n",
        "2. {chunk_2}\n",
        "\n",
        "Is this condition dangerous? What should the user do next?\n",
        "\"\"\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"OpenRouter-Model\": model\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful and medically accurate assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 200\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "        return response.json()['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        print(f\"LLM API error: {e}\")\n",
        "        # Provide a fallback response if the API call fails\n",
        "        danger_level = \"potentially concerning\" if label == \"melanoma\" else \"likely benign\"\n",
        "        return f\"Error getting detailed analysis. Based on the image classification: This appears to be {label}, which is {danger_level}. Please consult a healthcare professional for proper diagnosis.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "rux33RTRv32D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = generate_llm_diagnosis(user_note=text, label=\"melanoma\", chunk_1=top_chunks[0][0], chunk_2=top_chunks[1][0])\n",
        "print(response)"
      ],
      "metadata": {
        "id": "U469hjNRoUUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Types of moles\n",
        "class_names = [\"benign\", \"nevus\", \"melanoma\"]\n",
        "\n",
        "# CNN to classify images\n",
        "image_model = models.efficientnet_b0(pretrained=True)\n",
        "image_model.classifier[1] = nn.Linear(image_model.classifier[1].in_features, len(class_names))  # match class count\n",
        "image_model.eval()\n",
        "\n",
        "# Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # normalization\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Label-to-description mapping (can be expanded)\n",
        "label_to_description = {\n",
        "    \"benign\": \"A non-cancerous skin lesion. Usually harmless and does not require treatment.\",\n",
        "    \"nevus\": \"A common mole, generally benign but should be monitored for changes.\",\n",
        "    \"melanoma\": \"Melanoma is a serious form of skin cancer that arises when pigment-producing cells mutate.\"\n",
        "}\n",
        "\n",
        "# CNN-based classification + LLM-like response\n",
        "def classify_skin_lesion(image, text_note):\n",
        "    if image is None:\n",
        "        return {}, \"Please upload an image for analysis\", \"\", \"\"\n",
        "\n",
        "    # Preprocess image\n",
        "    img_tensor = transform(image).unsqueeze(0)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        output = image_model(img_tensor)\n",
        "        probs = torch.nn.functional.softmax(output, dim=1)\n",
        "        pred_idx = torch.argmax(probs, dim=1).item()\n",
        "        label = class_names[pred_idx]\n",
        "\n",
        "    # Get top chunks based on user notes\n",
        "    top_chunks = []\n",
        "    if text_note and text_note.strip():\n",
        "        top_chunks = get_top_k_chunks(text_note, k=2)\n",
        "    else:\n",
        "        # If no notes, use label as the search query\n",
        "        top_chunks = get_top_k_chunks(f\"Information about {label}\", k=2)\n",
        "\n",
        "    # Extract chunk texts\n",
        "    chunk_1 = top_chunks[0][0] if len(top_chunks) > 0 else \"No relevant information found.\"\n",
        "    chunk_2 = top_chunks[1][0] if len(top_chunks) > 1 else \"No additional information found.\"\n",
        "\n",
        "    # Get LLM-generated response\n",
        "    llm_response = generate_llm_diagnosis(text_note, label, chunk_1, chunk_2)\n",
        "\n",
        "    return {label: float(probs[0][pred_idx])}, llm_response, chunk_1, chunk_2\n",
        "\n",
        "# CSS for better styling\n",
        "css = \"\"\"\n",
        ".gradio-container {max-width: 900px !important}\n",
        ".disclaimer {color: red; font-weight: bold; text-align: center; margin: 20px 0;}\n",
        "\"\"\"\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks(css=css) as interface:\n",
        "    gr.Markdown(\"# Skin Lesion Analysis Tool\")\n",
        "    gr.Markdown(\"Upload an image of a skin lesion for analysis. Add any notes about symptoms or concerns.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            input_image = gr.Image(type=\"pil\", label=\"Upload Skin Lesion Image\")\n",
        "            input_text = gr.Textbox(lines=3, label=\"Additional Notes (symptoms, concerns, etc.)\")\n",
        "            submit_btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            output_class = gr.Label(label=\"Classification Result\")\n",
        "            output_llm = gr.Textbox(label=\"Medical Assessment\", lines=8)\n",
        "\n",
        "        with gr.Column(\"Relevant Medical Information\"):\n",
        "          chunk1 = gr.Textbox(label=\"Primary Reference\", lines=10)\n",
        "          chunk2 = gr.Textbox(label=\"Secondary Reference\", lines=10)\n",
        "    gr.Markdown(\"\"\"<div class=\"disclaimer\">DISCLAIMER: This tool is for educational purposes only and should not replace professional medical advice. Always consult a healthcare professional for proper diagnosis and treatment.</div>\"\"\")\n",
        "\n",
        "    # Set up the submission action\n",
        "    submit_btn.click(\n",
        "        fn=classify_skin_lesion,\n",
        "        inputs=[input_image, input_text],\n",
        "        outputs=[output_class, output_llm, chunk1, chunk2]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"### How to use\")\n",
        "    gr.Markdown(\"\"\"\n",
        "    1. Upload a clear, well-lit photo of the skin lesion\n",
        "    2. Add any relevant notes about symptoms or concerns\n",
        "    3. Click 'Analyze' to get results\n",
        "    4. Review the assessment and consider following up with a healthcare professional\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"To enable LLM functionality, set your OpenRouter API key as an environment variable:\")\n",
        "    print(\"export OPENROUTER_API_KEY='your_api_key_here'\")\n",
        "\n",
        "    interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "qoDGlmahWAL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}